{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning a Linear Function via Perceptron\n",
    "### By Russell Marvin\n",
    "\n",
    "My goal here is to write a program that implements a perceptron capable of 'learning' certain Boolean functions like AND, OR, NAND and NOR.\n",
    "\n",
    "My implementation includes `sop()`, a function that calculates sum of products for an instance and uses a linear step function for activation, returning a y value which serves as a predicted outcome for the instance. \n",
    "\n",
    "Next is the `error()` function that implements the delta rule (learnrate(t-y)input) to calculate a set of weight updates for the weights on the edges from the bias, x1 and x2: [w0,w1,w2]. It it called error because it uses the difference between target and predicted outcome (t-y) in the delta rule. Learnrate is set to .1 automatically. Input loops through each value of the row (instance) except row[3] which is the target value. Essentially, input is first 'bias', then 'x1', then 'x2'. \n",
    "\n",
    "Finally is the `perceptron_learning()` function which takes an input data (numpy array of boolean truth table) and weights (randomly initialized between -.01 and .01 in this case)) for each edge (w0,w1,w2). This function loops through the rows, calling `error()` (and thus calling `sop()`), keeping track of errors found (by checking whether weight updates are all 0). If errors are 0 for an entire epoch (cycle through all instances), then the function stops. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00909995557006964, -0.002463019950089045, -0.0026195476144377098] are our initial weights.\n",
      "--------------------\n",
      "Inputs for x1 and x2 in this instance: 0 0\n",
      "Change in weight for [w0,w1,w2]: [0. 0. 0.]\n",
      "Current weights: [-0.00909996 -0.00246302 -0.00261955]\n",
      "--------------------\n",
      "Inputs for x1 and x2 in this instance: 0 1\n",
      "Change in weight for [w0,w1,w2]: [0. 0. 0.]\n",
      "Current weights: [-0.00909996 -0.00246302 -0.00261955]\n",
      "--------------------\n",
      "Inputs for x1 and x2 in this instance: 1 0\n",
      "Change in weight for [w0,w1,w2]: [0. 0. 0.]\n",
      "Current weights: [-0.00909996 -0.00246302 -0.00261955]\n",
      "--------------------\n",
      "Inputs for x1 and x2 in this instance: 1 1\n",
      "There was an error on this instance because 1 != our perceptrons predicted output.\n",
      "Change in weight for [w0,w1,w2]: [0.1 0.1 0.1]\n",
      "Current weights: [0.09090004 0.09753698 0.09738045]\n",
      "1 Errors in this epoch.\n",
      "1 Epochs have passed.\n",
      "MUST. KEEP. ITERATING.\n",
      "--------------------\n",
      "Inputs for x1 and x2 in this instance: 0 0\n",
      "There was an error on this instance because 0 != our perceptrons predicted output.\n",
      "Change in weight for [w0,w1,w2]: [-0.1 -0.  -0. ]\n",
      "Current weights: [-0.00909996  0.09753698  0.09738045]\n",
      "--------------------\n",
      "Inputs for x1 and x2 in this instance: 0 1\n",
      "There was an error on this instance because 0 != our perceptrons predicted output.\n",
      "Change in weight for [w0,w1,w2]: [-0.1 -0.  -0.1]\n",
      "Current weights: [-0.10909996  0.09753698 -0.00261955]\n",
      "--------------------\n",
      "Inputs for x1 and x2 in this instance: 1 0\n",
      "Change in weight for [w0,w1,w2]: [0. 0. 0.]\n",
      "Current weights: [-0.10909996  0.09753698 -0.00261955]\n",
      "--------------------\n",
      "Inputs for x1 and x2 in this instance: 1 1\n",
      "There was an error on this instance because 1 != our perceptrons predicted output.\n",
      "Change in weight for [w0,w1,w2]: [0.1 0.1 0.1]\n",
      "Current weights: [-0.00909996  0.19753698  0.09738045]\n",
      "3 Errors in this epoch.\n",
      "2 Epochs have passed.\n",
      "MUST. KEEP. ITERATING.\n",
      "--------------------\n",
      "Inputs for x1 and x2 in this instance: 0 0\n",
      "Change in weight for [w0,w1,w2]: [0. 0. 0.]\n",
      "Current weights: [-0.00909996  0.19753698  0.09738045]\n",
      "--------------------\n",
      "Inputs for x1 and x2 in this instance: 0 1\n",
      "There was an error on this instance because 0 != our perceptrons predicted output.\n",
      "Change in weight for [w0,w1,w2]: [-0.1 -0.  -0.1]\n",
      "Current weights: [-0.10909996  0.19753698 -0.00261955]\n",
      "--------------------\n",
      "Inputs for x1 and x2 in this instance: 1 0\n",
      "There was an error on this instance because 0 != our perceptrons predicted output.\n",
      "Change in weight for [w0,w1,w2]: [-0.1 -0.1 -0. ]\n",
      "Current weights: [-0.20909996  0.09753698 -0.00261955]\n",
      "--------------------\n",
      "Inputs for x1 and x2 in this instance: 1 1\n",
      "There was an error on this instance because 1 != our perceptrons predicted output.\n",
      "Change in weight for [w0,w1,w2]: [0.1 0.1 0.1]\n",
      "Current weights: [-0.10909996  0.19753698  0.09738045]\n",
      "3 Errors in this epoch.\n",
      "3 Epochs have passed.\n",
      "MUST. KEEP. ITERATING.\n",
      "--------------------\n",
      "Inputs for x1 and x2 in this instance: 0 0\n",
      "Change in weight for [w0,w1,w2]: [0. 0. 0.]\n",
      "Current weights: [-0.10909996  0.19753698  0.09738045]\n",
      "--------------------\n",
      "Inputs for x1 and x2 in this instance: 0 1\n",
      "Change in weight for [w0,w1,w2]: [0. 0. 0.]\n",
      "Current weights: [-0.10909996  0.19753698  0.09738045]\n",
      "--------------------\n",
      "Inputs for x1 and x2 in this instance: 1 0\n",
      "There was an error on this instance because 0 != our perceptrons predicted output.\n",
      "Change in weight for [w0,w1,w2]: [-0.1 -0.1 -0. ]\n",
      "Current weights: [-0.20909996  0.09753698  0.09738045]\n",
      "--------------------\n",
      "Inputs for x1 and x2 in this instance: 1 1\n",
      "There was an error on this instance because 1 != our perceptrons predicted output.\n",
      "Change in weight for [w0,w1,w2]: [0.1 0.1 0.1]\n",
      "Current weights: [-0.10909996  0.19753698  0.19738045]\n",
      "2 Errors in this epoch.\n",
      "4 Epochs have passed.\n",
      "MUST. KEEP. ITERATING.\n",
      "--------------------\n",
      "Inputs for x1 and x2 in this instance: 0 0\n",
      "Change in weight for [w0,w1,w2]: [0. 0. 0.]\n",
      "Current weights: [-0.10909996  0.19753698  0.19738045]\n",
      "--------------------\n",
      "Inputs for x1 and x2 in this instance: 0 1\n",
      "There was an error on this instance because 0 != our perceptrons predicted output.\n",
      "Change in weight for [w0,w1,w2]: [-0.1 -0.  -0.1]\n",
      "Current weights: [-0.20909996  0.19753698  0.09738045]\n",
      "--------------------\n",
      "Inputs for x1 and x2 in this instance: 1 0\n",
      "Change in weight for [w0,w1,w2]: [0. 0. 0.]\n",
      "Current weights: [-0.20909996  0.19753698  0.09738045]\n",
      "--------------------\n",
      "Inputs for x1 and x2 in this instance: 1 1\n",
      "Change in weight for [w0,w1,w2]: [0. 0. 0.]\n",
      "Current weights: [-0.20909996  0.19753698  0.09738045]\n",
      "1 Errors in this epoch.\n",
      "5 Epochs have passed.\n",
      "MUST. KEEP. ITERATING.\n",
      "--------------------\n",
      "Inputs for x1 and x2 in this instance: 0 0\n",
      "Change in weight for [w0,w1,w2]: [0. 0. 0.]\n",
      "Current weights: [-0.20909996  0.19753698  0.09738045]\n",
      "--------------------\n",
      "Inputs for x1 and x2 in this instance: 0 1\n",
      "Change in weight for [w0,w1,w2]: [0. 0. 0.]\n",
      "Current weights: [-0.20909996  0.19753698  0.09738045]\n",
      "--------------------\n",
      "Inputs for x1 and x2 in this instance: 1 0\n",
      "Change in weight for [w0,w1,w2]: [0. 0. 0.]\n",
      "Current weights: [-0.20909996  0.19753698  0.09738045]\n",
      "--------------------\n",
      "Inputs for x1 and x2 in this instance: 1 1\n",
      "Change in weight for [w0,w1,w2]: [0. 0. 0.]\n",
      "Current weights: [-0.20909996  0.19753698  0.09738045]\n",
      "0 Errors in this epoch.\n",
      "6 Epochs have passed.\n",
      "Done!!!\n"
     ]
    }
   ],
   "source": [
    "# practice\n",
    "import numpy as np\n",
    "import random \n",
    "\n",
    "#and data in format [1,x1,x2,target] - I include 1 as bias input for future use\n",
    "and_array = np.array([[1,0,0,0],[1,0,1,0],[1,1,0,0],[1,1,1,1]])\n",
    "#print(and_array,'and array')\n",
    "\n",
    "or_array = np.array([[1,0,0,0],[1,0,1,1],[1,1,0,1],[1,1,1,1]])\n",
    "#print(or_array,'or array')\n",
    "\n",
    "nand_array = np.array([[1,0,0,1],[1,0,1,1],[1,1,0,1],[1,1,1,0]])\n",
    "#print(nand_array,'nand array')\n",
    "\n",
    "nor_array = np.array([[1,0,0,1],[1,0,1,0],[1,1,0,0],[1,1,1,0]])\n",
    "#print(nor_array,'nor array')\n",
    "\n",
    "\n",
    "#sum of products function to determine y\n",
    "def sop(row,weights):\n",
    "    S = row[1]*weights[1] + row[2]*weights[2] + weights[0]\n",
    "    #print(S)\n",
    "    if S > 0:\n",
    "        y = 1\n",
    "    else:\n",
    "        y = 0\n",
    "    #print(y)\n",
    "    return y\n",
    "\n",
    "#error function to determine weight updates using error\n",
    "def error(row,weights):\n",
    "    learn_rate = .1\n",
    "    #for now i'll save our deltas in a list\n",
    "    deltas = []\n",
    "    #call sop function for output\n",
    "    y = sop(row,weights)\n",
    "    for input in row[:3]:\n",
    "        #implement delta rule: (learnrate*(target-output)*input)\n",
    "        #remember, row[3] is target, given the structure/format of data I used\n",
    "        delta = learn_rate*(row[3]-y)*input\n",
    "        #simply add this weight update value to the list\n",
    "        deltas.append(delta)\n",
    "  \n",
    "    return deltas\n",
    "\n",
    "\n",
    "#mother of all functions, learns boolean operators\n",
    "def perceptron_learning(data,weights):\n",
    "    print(weights,'are our initial weights.')\n",
    "    epochs = 0\n",
    "    while True:\n",
    "        #count errors for this epoch, initialize to 0\n",
    "        errors = 0\n",
    "        #loop through all rows (instances) \n",
    "        for row in data:\n",
    "            #convert our weights to numpy array for addition later on\n",
    "            weights_array = np.array(weights)\n",
    "            [print('--------------------')]\n",
    "            print('Inputs for x1 and x2 in this instance:',row[1],row[2])\n",
    "            #convert to array, same as above\n",
    "            deltas_array = np.array(error(row,weights))\n",
    "            #if the weight update values (aka deltas) are NOT ALL 0 \n",
    "            #(meaning there was some adjustment needed, then add to 'errors' count\n",
    "            if not (deltas_array == np.array([0,0,0])).all():\n",
    "                print('There was an error on this instance because',row[3],'!= our perceptrons predicted output.')\n",
    "                errors +=1\n",
    "            print('Change in weight for [w0,w1,w2]:',deltas_array)\n",
    "            #add deltas to weights so that our new 'weights' object is updated properly\n",
    "            weights = weights_array + deltas_array\n",
    "            print('Current weights:',weights)\n",
    "        epochs +=1\n",
    "        print(errors,'Errors in this epoch.')\n",
    "        print(epochs,'Epochs have passed.')\n",
    "        #Just having some fun:\n",
    "        if errors > 0:\n",
    "            print('MUST. KEEP. ITERATING.')\n",
    "        else:\n",
    "            print('Done!!!')\n",
    "        #if the current epoch has no errors, then end\n",
    "        if errors == 0:\n",
    "            break\n",
    "        \n",
    "\n",
    "        \n",
    "#define start weights\n",
    "start_weights = [random.uniform((-.01),.01),random.uniform((-.01),.01),random.uniform((-.01),.01)]\n",
    "perceptron_learning(and_array,start_weights) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, this went quite well. I didn't run into any real issues, found some useful things in numpy like `.all()` and `.any()` for comparing arrays and `.array()` to turn lists into arrays, allows addition (and other operations of course) by index.\n",
    "\n",
    "This can learn linearly separable two-input Boolean functions. Cannot learn XOR (not linearly separable). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "552eff63ae26b1f7715ef9da8940d59e9923cc9f3696b79d9372b91e56e1a4b8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
