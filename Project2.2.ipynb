{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2.2 - Naive Bayes for Classification\n",
    "### By: Russell Marvin\n",
    "\n",
    "Here's the code for my Naive Bayes Classifier components - the functions that are used explicitly in this classifier will include `attribute_col()`, `prior()`, `likelihood()`, `evidence`, and `posterior()`.\n",
    "\n",
    "`attribute_col()` returns the correct column of attributes that corresponds with a given attribute value a<sub>i</sub> and the index of that column in the data (ndarray). This is not an ideal way to achieve this goal but it works for this function. I'm guessing there's a function I'm not familiar with or more elegant code that could have done this for me. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#opening file, we can change this to input(\"what file?\") if we want it to use different files\n",
    "file_path = open(\"fishing.txt\")\n",
    "#use numpy genfromtxt to turn .txt into arrays, dtype specifies string values (vs int, float, etc)\n",
    "data = np.genfromtxt(file_path, dtype = str)\n",
    "\n",
    "#defining all data in target variable column (first col)\n",
    "target = data[1:,0]\n",
    "\n",
    "#defining all data in an array without names of cols\n",
    "all_data = data[1:,:]\n",
    "\n",
    "priors = {}\n",
    "\n",
    "#finding instance with each attribute value \n",
    "def attribute_col(asubi):\n",
    "    #list of attribute values for each column initialized\n",
    "    attr_col = []\n",
    "    for i in range(len(all_data)):\n",
    "        for j in range(len(all_data[i])):\n",
    "            #checking if that value == our attribute value of interest, if so, save col as j\n",
    "            if all_data[i,j] == asubi:\n",
    "                col = j\n",
    "                #break to save j so we only pull attr in col j\n",
    "                break\n",
    "    #append values for each row given column j\n",
    "    for i in (all_data):\n",
    "        attr_col.append(i[col])\n",
    "    #return all possible attributes for that attr column, column index\n",
    "\n",
    "    return attr_col, col\n",
    "    \n",
    "\n",
    "#prior function for prob of each class value / all training examples\n",
    "def prior(csubj):\n",
    "    #loop through unique values of classes and count when the value is equal to each class_ (outcome)\n",
    "    for class_ in np.unique(target):\n",
    "        class_count = sum(target == class_)\n",
    "        #calculate num in each class / num training examples\n",
    "        priors[class_] = class_count / (data.shape[0] - 1)\n",
    "    return priors[csubj]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# likelhood: estimate the probability of each attribute value ai, given a class of type j\n",
    "# aka #asubi / #csubj\n",
    "def likelihood(asubi, csubj):\n",
    "    #loop through feature columns\n",
    "    temp_dict = {}\n",
    "    #for every unique attribute value in the column which includes asubi\n",
    "    for attr in np.unique(attribute_col(asubi)[0]):\n",
    "        #create dict key w/ each unique value, start count at 0\n",
    "        temp_dict[attr] = 0\n",
    "    #\n",
    "    for i in range(len(all_data)):\n",
    "        if all_data[i,0] == csubj:\n",
    "            #grab the 'j' from attribute_col, which indexes certain column with asubi, add 1 in that dict value\n",
    "            temp_dict[all_data[i,attribute_col(asubi)[1]]] +=1\n",
    "\n",
    "    #return # asubi / total possible values given class csubj\n",
    "\n",
    "    return temp_dict[asubi]/ sum(temp_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evidence: estimate the probability of each attribute value: \n",
    "#P(ai) = #ai / #training examples\n",
    "#need to count #ai aka number of instances of each value of attribute (count 'A's and 'B's)\n",
    "def evidence(asubi):\n",
    "    count = 0\n",
    "    for i in attribute_col(asubi)[0]:\n",
    "        if asubi == i:\n",
    "            count +=1\n",
    "    return count/len(attribute_col(asubi)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior(csubj, asubi): \n",
    "    return (likelihood(asubi, csubj) * prior(csubj)) / (evidence(asubi))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn Phase\n",
    "### 1. Estimate the probability of each class: P(cj) = #cj / #training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'No': 0.42857142857142855, 'Yes': 0.5714285714285714}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use a dictionary to hold class probabilities\n",
    "temp_dict2 = {}\n",
    "def learn_1():\n",
    "    for csubj in np.unique(target):\n",
    "        temp_dict2[csubj] = prior(csubj)\n",
    "    #return a dictionary with keys = class values and values = probability\n",
    "    return temp_dict2\n",
    "learn_1()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Estimate the probability of each attribute value ai, given a class of type j: P(ai | cj) = #ai / #cj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'No': {'Cloudy': 0.16666666666666666,\n",
       "  'Cold': 0.6666666666666666,\n",
       "  'Cool': 0.5,\n",
       "  'Hot': 0.3333333333333333,\n",
       "  'Moderate': 0.3333333333333333,\n",
       "  'Rainy': 0.5,\n",
       "  'Strong': 0.3333333333333333,\n",
       "  'Sunny': 0.3333333333333333,\n",
       "  'Warm': 0.16666666666666666,\n",
       "  'Weak': 0.6666666666666666},\n",
       " 'Yes': {'Cloudy': 0.125,\n",
       "  'Cold': 0.375,\n",
       "  'Cool': 0.125,\n",
       "  'Hot': 0.625,\n",
       "  'Moderate': 0.5,\n",
       "  'Rainy': 0.125,\n",
       "  'Strong': 0.75,\n",
       "  'Sunny': 0.75,\n",
       "  'Warm': 0.375,\n",
       "  'Weak': 0.25}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create ANOTHER dictionary to store likelihoods\n",
    "temp_dict3 = {}\n",
    "def learn_2():\n",
    "    for csubj in np.unique(target):\n",
    "        #new dictionary nested within each class value key holding all attribute likelihoods\n",
    "        temp_dict3[csubj] = {}\n",
    "        for asubi in np.unique(all_data[:,1:]):\n",
    "            #loop through all attribute values in each col (except target first col) and assign that dict value to the `likelihood()`  of that attribute value given that class\n",
    "            temp_dict3[csubj][asubi] = likelihood(asubi,csubj)\n",
    "    #return the entire dictionary to display readable likelihoods\n",
    "    return temp_dict3 \n",
    "learn_2()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a set of probabilities for each class, and a set of likelihoods for every attribute value given each class type j. This is what we need to use to classify a new instance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify Phase (applied to new Instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The conditional probability that the class is Yes, given the observed attribute values is :\n",
      " 0.025 / (0.025 + 0.008) = 0.76\n"
     ]
    }
   ],
   "source": [
    "#calculate all class probabilities for an instance\n",
    "def classify(instance):\n",
    "    temp_object = learn_2()\n",
    "    temp_dict5 = {}\n",
    "    for csubj in np.unique(target):\n",
    "        #calculate prob of each class (using temp_dict2 from learn_1), using prob of observed data\n",
    "        temp_dict5[csubj] = (temp_dict2[csubj]) * temp_object[csubj][instance[0]] * temp_object[csubj][instance[1]] * temp_object[csubj][instance[2]] * temp_object[csubj][instance[3]]\n",
    "    #grab the key of the largest value in temp_dict5 (max probability for this instance)\n",
    "    #grab key for smallest value in temp_dict5 (min prob for instance)\n",
    "    maximum = max(temp_dict5, key = temp_dict5.get)\n",
    "    minimum = min(temp_dict5, key = temp_dict5.get)\n",
    "    #return the conditional probability of the max class as calculated by the relative probabilities of each class\n",
    "    return print(f'The conditional probability that the class is {maximum}, given the observed attribute values is :\\n {round(temp_dict5[maximum],3)} / ({round(temp_dict5[maximum],3)} + {round(temp_dict5[minimum],3)}) = {round(temp_dict5[maximum] / (temp_dict5[maximum] + temp_dict5[minimum]),3)}')\n",
    "classify(['Strong','Hot','Cool','Sunny'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now calculated the conditional probability that a new instance belongs to a certain class, aka the most likely class for this new instance given our observed data and assuming the conditional independence of our attribute values."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "552eff63ae26b1f7715ef9da8940d59e9923cc9f3696b79d9372b91e56e1a4b8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
