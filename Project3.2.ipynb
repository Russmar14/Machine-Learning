{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 pt. 2 - Decision Stump Construction via ID3\n",
    "### By Russell Marvin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are our functions for entropy and InfoGain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#opening file, we can change this to input(\"what file?\") if we want it to use different files\n",
    "file_path = open(\"treatment.txt\")\n",
    "#use numpy genfromtxt to turn .txt into arrays, dtype specifies string values (vs int, float, etc)\n",
    "data = np.genfromtxt(file_path, dtype = str)\n",
    "#defining all data in an array without names of cols\n",
    "all_data = data[1:,:]\n",
    "#print(all_data)\n",
    "\n",
    "\n",
    "def entropy(data):\n",
    "    #count how frequent each outcome is using a dict\n",
    "    count_freq = {}\n",
    "    for instance in data:\n",
    "        value = instance[0]\n",
    "        #add 1 to the count for this value of the target variable\n",
    "        if value in count_freq:\n",
    "            count_freq[value] +=1\n",
    "        #add a count = 1 and a new key corresponding w/ this unseen value of target var\n",
    "        else:\n",
    "            count_freq[value] = 1\n",
    "    total_examples = len(data)\n",
    "    #calculate probabilities\n",
    "    probabilities = [i / total_examples for i in count_freq.values()]\n",
    "    #loop through probabilities and apply prob*log2(prob), then calculate neg sum of them\n",
    "    entropy = -sum(prob * np.log2(prob) for prob in probabilities)\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def information_gain(data, attr_index):\n",
    "  # Define the attribute and label columns for use\n",
    "    attr_col = data[:, attr_index]\n",
    "    target_col = data[:, 0]\n",
    "    #Count the frequency of each attribute value\n",
    "    unique_values, value_counts = np.unique(attr_col, return_counts=True)\n",
    "    #compute the entropy of the whole dataset (target or 'Oracle' column)\n",
    "    set_entropy = entropy(target_col)\n",
    "    #count examples\n",
    "    total_examples = len(data)\n",
    "    #use a list to store entropy values to be multiplied by weight\n",
    "    temp_entropies = []\n",
    "    #save these intermediate entropy values in a dictionary to print later\n",
    "    dict_ent = {}\n",
    "    #iterate through the lists together (same length of 2) and calculate the entropy for each subset\n",
    "    for val, count in zip(unique_values, value_counts):\n",
    "        #examine only the rows for each unique value at a time (subset), use its corresponding count to calculate its weight\n",
    "        subset = data[attr_col == val]\n",
    "        #how much of the data does this subset constitute?\n",
    "        weight = count / total_examples\n",
    "        temp_entropy = entropy(subset[:, 0])\n",
    "        #store these entropy values in our temporary dictionary\n",
    "        dict_ent[val] = temp_entropy\n",
    "        #add to list each weighted entropy \n",
    "        temp_entropies.append(weight * temp_entropy)\n",
    "    total_entropies = np.sum(temp_entropies)\n",
    "    # calculate information gain using summed temporary entropies\n",
    "    info_gain = set_entropy - total_entropies\n",
    "\n",
    "    return info_gain, attr_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create an implementation of the ID3 for a decision stump - implement the first level of the ID3 algorithm for decision tree construction. In other\n",
    "words, perform all steps that stop short of the recursive call in the original algorithm.\n",
    "\n",
    "Modified ID3 (S)\n",
    " - choose the attribute a that maximizes the Information Gain of S\n",
    " -  let attribute a be the decision for the root node\n",
    " - add a branch from the root node for each possible value v of attribute a \n",
    " - for each branch:\n",
    "     - “sort” examples down the branches based on their value v of attribute a \n",
    " - classify each terminal node with its majority label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `modified_id3()` function takes a labeled classification dataset `my_data` in the form of a string dictating the file path and a `Yes` and `No` as input, with Yes and No corresponding to what your dataset uses to indicate classification - 1/0, Yes/No, Pos/Neg, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_id3(my_data, Yes, No):\n",
    "    file_path = open(my_data)\n",
    "    #use numpy genfromtxt to turn .txt into arrays, dtype specifies string values (vs int, float, etc)\n",
    "    data = np.genfromtxt(file_path, dtype = str)\n",
    "    #defining labels of our dataset\n",
    "    labels = data[0,:]\n",
    "    #defining all data in an array without names of cols\n",
    "    data = data[1:,:]\n",
    "    #let's save our attribute_cols and info gain in a dict\n",
    "    ig_dict = {}\n",
    "    #for the value of every col in our data...\n",
    "    for i in range(data.shape[1]):\n",
    "        #calculate the infogain of each col and save their index\n",
    "        ig, col = information_gain(data,i)\n",
    "        #ignore the first column (target vals, not an attr)\n",
    "        if col != 0:\n",
    "            ig_dict[col] = ig\n",
    "            #print the intermediate value (infogain) for each attribute\n",
    "            print(ig, f'is the infogain of {labels[col]}')\n",
    "    best_col = (max(ig_dict, key = ig_dict.get))\n",
    "    print(f'The decision node is {labels[best_col]}, aka the best attribute to choose.')\n",
    "    #Now I need to grab the index (row) of all values of each v for this a\n",
    "    #and assign them, classify based on majority\n",
    "    values = np.unique(data[:,best_col])\n",
    "    #this dict stores Yes/No counts for each subset with attr val v\n",
    "    temp_dict = {}\n",
    "    #this dict stores list of row index values belonging to each attr value v\n",
    "    temp_dict2 = {}\n",
    "    for value in values:\n",
    "        #initialize each value to 0\n",
    "        temp_dict[value] = {Yes:0,No:0}\n",
    "        #initialize list for each value\n",
    "        temp_dict2[value] = []\n",
    "        #select only items with 'value' as their value\n",
    "        index = np.where(data == value)[0]\n",
    "        #for each row in that attribute, \n",
    "        for i in index:\n",
    "            #if the target label is Yes...\n",
    "            if data[i,0] == Yes:\n",
    "                #I have to add 1 to i here so it fits the naming schema in the HW/tutorial\n",
    "                #where 'data 1' is the first example and so on... It's actually the second \n",
    "                #row in the dataset and the 0th in index. This is trivial, but just for the \n",
    "                #sake of comprehension and validation of results, I'll add 1\n",
    "                temp_dict[value][Yes] +=1\n",
    "                #add that index value i to the list for this attr value v\n",
    "                temp_dict2[value].append(i + 1)\n",
    "            elif data[i,0] == No:\n",
    "                temp_dict[value][No] +=1\n",
    "                temp_dict2[value].append(i + 1)\n",
    "    #print(temp_dict2)\n",
    "    for k,v in temp_dict.items():\n",
    "        numerator = v[Yes]\n",
    "        denominator = numerator + v[No]\n",
    "        if denominator == 0:\n",
    "            proportion_yes == 0\n",
    "        else:\n",
    "            proportion_yes = numerator/denominator\n",
    "        if proportion_yes >.5:\n",
    "            stump = print(f'One branch is: {k}, which is labeled: {Yes}, including data instances: {temp_dict2[k]}')\n",
    "        elif proportion_yes <.5:\n",
    "            stump = print(f'One branch is: {k}, which is labeled: {No}, including data instances: {temp_dict2[k]}')\n",
    "        elif proportion_yes == .5:\n",
    "            stump = print(k,\"Undecided, due to 50/50 split\")  \n",
    "    return stump\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function creates a sentence describing each branch in the stump (including the decision node) and the label for its constituent members (with them listed as well). This is an easily readable way to display the results as an alternative to creating a tree/stump. \n",
    "\n",
    "Let's try it on our treatment data from HW7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01997309402197489 is the infogain of Pulse\n",
      "0.9709505944546686 is the infogain of BP\n",
      "0.4199730940219749 is the infogain of Age\n",
      "The decision node is BP, aka the best attribute to choose.\n",
      "One branch is: Abnormal, which is labeled: Neg, including data instances: [4, 5]\n",
      "One branch is: Normal, which is labeled: Pos, including data instances: [1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "modified_id3(\"treatment.txt\", \"Pos\", \"Neg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now on the fishing data from the tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12808527889139443 is the infogain of Wind\n",
      "0.06105378373381021 is the infogain of Air\n",
      "0.12808527889139443 is the infogain of Water\n",
      "0.2638091738835462 is the infogain of Sky\n",
      "The decision node is Sky, aka the best attribute to choose.\n",
      "One branch is: Cloudy, which is labeled: Yes, including data instances: [3]\n",
      "One branch is: Rainy, which is labeled: No, including data instances: [4, 5, 6, 10, 14]\n",
      "One branch is: Sunny, which is labeled: Yes, including data instances: [1, 2, 7, 8, 9, 11, 12, 13]\n"
     ]
    }
   ],
   "source": [
    "modified_id3(\"fishing.txt\", \"Yes\", \"No\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally on this new donors dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17549700417502345 is the infogain of Status\n",
      "0.0031147587638322705 is the infogain of Party\n",
      "The decision node is Status, aka the best attribute to choose.\n",
      "One branch is: Family, which is labeled: Yes, including data instances: [3, 6, 9, 10, 14, 16, 20]\n",
      "One branch is: Married, which is labeled: No, including data instances: [2, 4, 5, 7, 8, 12, 13, 17, 18, 19]\n",
      "One branch is: Single, which is labeled: No, including data instances: [1, 11, 15]\n"
     ]
    }
   ],
   "source": [
    "modified_id3(\"donors.txt\", \"Yes\", \"No\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems/Data structures: \n",
    "\n",
    "This portion of the project went well. I felt I was able to generalize this well to each dataset, using the unique target variable labels (referred to as `Yes` and `No` in my `modified_id3()` function). I also changed made the file path dynamic such that the user can input a string indicating the file path into this function. This, combined with the aforementioned labels as inputs makes the function generally applicable to data with the same format (row/col positioning of labels, target, etc.) but with variable numbers of attributes and attribute values num. \n",
    "\n",
    "I used dictionaries for my `modified_id3` because I found them the most intuitive way to store my data (to access later on). I used `numpy.where()` to select certain values and found [this](https://www.digitalocean.com/community/tutorials/python-numpy-where) to be more useful than the documentation page. \n",
    "\n",
    "The format I decided on with print statements and sentences describin the stump is somewhat difficult to interpret, I'd prefer reading an actual tree/stump."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "552eff63ae26b1f7715ef9da8940d59e9923cc9f3696b79d9372b91e56e1a4b8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
